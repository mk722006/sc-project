{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No null values found in the C:\\Users\\algo\\Desktop\\VS Code\\Task\\Philly Deals to email append._processed.csv composite key.\n",
      "No duplicates found in the C:\\Users\\algo\\Desktop\\VS Code\\Task\\Philly Deals to email append._processed.csv composite key.\n",
      "No null values found in the C:\\Users\\algo\\Desktop\\VS Code\\Task\\sql_phoenix_20230921_141556.xlsx composite key.\n",
      "No duplicates found in the C:\\Users\\algo\\Desktop\\VS Code\\Task\\sql_phoenix_20230921_141556.xlsx composite key.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to clean and check for null values and duplicates\n",
    "def check_file(file_path, composite_key_columns):\n",
    "    # Read the file into a DataFrame\n",
    "    file = pd.read_csv(file_path) if file_path.endswith('.csv') else pd.read_excel(file_path)\n",
    "    \n",
    "    # Convert column names to lowercase\n",
    "    file.columns = file.columns.str.strip().str.lower()\n",
    "\n",
    "    # Create a composite key\n",
    "    file['composite_key'] = file[composite_key_columns].apply(tuple, axis=1)\n",
    "\n",
    "    # Clean the DataFrame by removing null values and duplicates in the composite key\n",
    "    file_cleaned = file.dropna(subset=['composite_key']).drop_duplicates(subset='composite_key', keep='first')\n",
    "\n",
    "    # Check if null values exist in the composite key columns\n",
    "    null_values = file[file['composite_key'].isnull()]\n",
    "\n",
    "    # Check for duplicates in the composite key columns\n",
    "    duplicates = file_cleaned[file_cleaned.duplicated(subset='composite_key', keep=False)]\n",
    "\n",
    "    # Print results\n",
    "    if not null_values.empty:\n",
    "        print(f\"Null values found in the {file_path} composite key:\")\n",
    "        print(null_values)\n",
    "    else:\n",
    "        print(f\"No null values found in the {file_path} composite key.\")\n",
    "\n",
    "    if not duplicates.empty:\n",
    "        print(f\"Duplicates found in the {file_path} composite key:\")\n",
    "        print(duplicates)\n",
    "    else:\n",
    "        print(f\"No duplicates found in the {file_path} composite key.\")\n",
    "\n",
    "# File paths and composite key columns\n",
    "csv_file_path = r'C:\\Users\\algo\\Desktop\\VS Code\\Task\\Philly Deals to email append._processed.csv'\n",
    "excel_file_path = r'C:\\Users\\algo\\Desktop\\VS Code\\Task\\sql_phoenix_20230921_141556.xlsx'\n",
    "composite_key_columns = [\"business name\", \"address\", \"city\", \"state\", \"postal code\", \"phone\"]\n",
    "\n",
    "# Check the CSV file\n",
    "check_file(csv_file_path, composite_key_columns)\n",
    "\n",
    "# Check the Excel file\n",
    "check_file(excel_file_path, composite_key_columns)\n",
    "\n",
    "# After checking and cleaning the files, now perform the right join with necessary columns\n",
    "def perform_right_join(csv_file_path, excel_file_path, composite_key_columns):\n",
    "    # Read the CSV file into a DataFrame\n",
    "    csv_file = pd.read_csv(csv_file_path)\n",
    "    # Convert column names to lowercase\n",
    "    csv_file.columns = csv_file.columns.str.strip().str.lower()\n",
    "\n",
    "    # Read the Excel file into a DataFrame\n",
    "    excel_file = pd.read_excel(excel_file_path)\n",
    "    # Convert column names to lowercase\n",
    "    excel_file.columns = excel_file.columns.str.strip().str.lower()\n",
    "\n",
    "    # Create composite keys for both DataFrames\n",
    "    csv_file['composite_key'] = csv_file[composite_key_columns].apply(tuple, axis=1)\n",
    "    excel_file['composite_key'] = excel_file[composite_key_columns].apply(tuple, axis=1)\n",
    "\n",
    "    # Perform a right join on the composite_key columns\n",
    "    merged_data = pd.merge(excel_file, csv_file, on='composite_key', how='right', suffixes=('_x', '_y'))\n",
    "\n",
    "    # Now, merged_data contains the result of the right join\n",
    "\n",
    "    # You can save the merged DataFrame to a new CSV file if needed\n",
    "    merged_data.to_csv(\"merged_data.csv\", index=False)\n",
    "\n",
    "# Perform the right join\n",
    "perform_right_join(csv_file_path, excel_file_path, composite_key_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
